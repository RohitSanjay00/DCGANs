{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNDaqYnRv4CJ"
      },
      "source": [
        "# DCGAN to generate face images\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2019/04/29<br>\n",
        "**Last modified:** 2021/01/01<br>\n",
        "**Description:** A simple DCGAN trained using `fit()` by overriding `train_step` on CelebA images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of available GPUs:  2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the number of available GPUs\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "num_gpus = len(gpus)\n",
        "\n",
        "# Print the number of GPUs\n",
        "print(\"Number of available GPUs: \", num_gpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0tK53L6v4CL"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "StcGoCI-v4CM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw9rr37Dv4CN"
      },
      "source": [
        "## Prepare CelebA data\n",
        "\n",
        "We'll use face images from the CelebA dataset, resized to 64x64."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuEPq1fiv4CO"
      },
      "source": [
        "Create a dataset from our folder, and rescale the images to the [0-1] range:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIeOq1B3v4CO",
        "outputId": "ef73a31c-d9b2-4348-a8dd-a99f9b1fb2dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 202599 files belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "dataset = keras.utils.image_dataset_from_directory(\n",
        "    \"C:/Users/ROHIT SANJAY/Documents/Rohit Michigan/Advanced AI/Project/Celeba_Faces/img_align_celeba\", label_mode=None, image_size=(64, 64), batch_size=32\n",
        ")\n",
        "dataset = dataset.map(lambda x: x / 255.0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWPTNQ27v4CP"
      },
      "source": [
        "Let's display a sample image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "5t4wFZXev4CP",
        "outputId": "2853932d-cf7a-4772-b2c5-84e54133594c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "for x in dataset:\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sglx5WJ-v4CP"
      },
      "source": [
        "## Create the discriminator\n",
        "\n",
        "It maps a 64x64 image to a binary classification score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2PBIn5av4CQ",
        "outputId": "8b0409e1-03d2-468e-d9e5-60c5d623b3f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 128)         262272    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 8193      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 404,801\n",
            "Trainable params: 404,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(64, 64, 3)),\n",
        "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        ")\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owVDbATQv4CQ"
      },
      "source": [
        "## Create the generator\n",
        "\n",
        "It mirrors the discriminator, replacing `Conv2D` layers with `Conv2DTranspose` layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex0fuB4Hv4CQ",
        "outputId": "4c3db4bc-248a-4ade-f1fa-428fa8580e37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_1 (Dense)             (None, 8192)              1056768   \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      262272    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      524544    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 64, 64, 3)         38403     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,979,651\n",
            "Trainable params: 3,979,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "latent_dim = 128\n",
        "\n",
        "generator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(latent_dim,)),\n",
        "        layers.Dense(8 * 8 * 128),\n",
        "        layers.Reshape((8, 8, 128)),\n",
        "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"generator\",\n",
        ")\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnYJKlrTv4CQ"
      },
      "source": [
        "## Override `train_step`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1FHP5eXYv4CR"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9YRt9ouv4CR"
      },
      "source": [
        "## Create a callback that periodically saves generated images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3KSilKVav4CR"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GANMonitor(keras.callbacks.Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        for i in range(self.num_img):\n",
        "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
        "            img.save(\"C:/Users/ROHIT SANJAY/Documents/Rohit Michigan/Advanced AI/Project/Generated_Images/generated_img_%03d_%d.png\" % (epoch+30, i))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgKUEkDxv4CS"
      },
      "source": [
        "## Train the end-to-end model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "t2VUAB8gv4CS",
        "outputId": "5a9b8702-9b10-4c96-b113-212a536bf8fc"
      },
      "outputs": [],
      "source": [
        "epochs = 10  # In practice, use ~100 epochs\n",
        "\n",
        "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gan.fit(\n",
        "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# for continuation of training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.GAN object at 0x000001E4B526C4C0>, because it is not built.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:/Users/ROHIT SANJAY/Documents/Rohit Michigan/Advanced AI/Project/gan_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:/Users/ROHIT SANJAY/Documents/Rohit Michigan/Advanced AI/Project/gan_model\\assets\n"
          ]
        }
      ],
      "source": [
        "# saving the model \n",
        "tf.saved_model.save(gan, 'C:/Users/ROHIT SANJAY/Documents/Rohit Michigan/Advanced AI/Project/gan_model')\n",
        "# Save the model weights\n",
        "gan.save_weights('C:/Users/ROHIT SANJAY/Documents/Rohit Michigan/Advanced AI/Project/gan_model_weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6332/6332 [==============================] - 3110s 491ms/step - d_loss: 0.6281 - g_loss: 0.9848\n",
            "Epoch 2/10\n",
            "6332/6332 [==============================] - 3299s 521ms/step - d_loss: 0.6274 - g_loss: 0.9837\n",
            "Epoch 3/10\n",
            "6332/6332 [==============================] - 3115s 492ms/step - d_loss: 0.6245 - g_loss: 0.9900\n",
            "Epoch 4/10\n",
            "6332/6332 [==============================] - 3255s 514ms/step - d_loss: 0.6181 - g_loss: 1.0093\n",
            "Epoch 5/10\n",
            "6332/6332 [==============================] - 3097s 489ms/step - d_loss: 0.6169 - g_loss: 1.0078\n",
            "Epoch 6/10\n",
            "6332/6332 [==============================] - 3155s 498ms/step - d_loss: 0.6173 - g_loss: 1.0118\n",
            "Epoch 7/10\n",
            "6332/6332 [==============================] - 3213s 507ms/step - d_loss: 0.6179 - g_loss: 1.0133\n",
            "Epoch 8/10\n",
            "6332/6332 [==============================] - 3250s 513ms/step - d_loss: 0.6128 - g_loss: 1.0098\n",
            "Epoch 9/10\n",
            "6332/6332 [==============================] - 3191s 504ms/step - d_loss: 0.6142 - g_loss: 1.0181\n",
            "Epoch 10/10\n",
            "6332/6332 [==============================] - 3234s 511ms/step - d_loss: 0.6128 - g_loss: 1.0200\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1e4b5180d00>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# to continue the trainin from the already existing weights\n",
        "gan.load_weights('C:/Users/ROHIT SANJAY/Documents/Rohit Michigan/Advanced AI/Project/gan_model_weights')\n",
        "gan.fit(\n",
        "    dataset, epochs=10, callbacks=[GANMonitor(num_img=5, latent_dim=latent_dim)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "dcgan_overriding_train_step",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
