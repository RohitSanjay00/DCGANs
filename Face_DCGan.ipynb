{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNDaqYnRv4CJ"
   },
   "source": [
    "# DCGAN to generate face images\n",
    "\n",
    "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
    "**Date created:** 2019/04/29<br>\n",
    "**Last modified:** 2021/01/01<br>\n",
    "**Description:** A simple DCGAN trained using `fit()` by overriding `train_step` on CelebA images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0tK53L6v4CL"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "StcGoCI-v4CM"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pw9rr37Dv4CN"
   },
   "source": [
    "## Prepare CelebA data\n",
    "\n",
    "We'll use face images from the CelebA dataset, resized to 64x64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuEPq1fiv4CO"
   },
   "source": [
    "Create a dataset from our folder, and rescale the images to the [0-1] range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIeOq1B3v4CO",
    "outputId": "ef73a31c-d9b2-4348-a8dd-a99f9b1fb2dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    \"C:/Users/ROHIT SANJAY/Documents/Rohit Michigan/Advanced AI/Project/Celeba_Faces/img_align_celeba\", label_mode=None, image_size=(64, 64), batch_size=32\n",
    ")\n",
    "dataset = dataset.map(lambda x: x / 255.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWPTNQ27v4CP"
   },
   "source": [
    "Let's display a sample image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "id": "5t4wFZXev4CP",
    "outputId": "2853932d-cf7a-4772-b2c5-84e54133594c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for x in dataset:\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sglx5WJ-v4CP"
   },
   "source": [
    "## Create the discriminator\n",
    "\n",
    "It maps a 64x64 image to a binary classification score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t2PBIn5av4CQ",
    "outputId": "8b0409e1-03d2-468e-d9e5-60c5d623b3f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 404,801\n",
      "Trainable params: 404,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(64, 64, 3)),\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owVDbATQv4CQ"
   },
   "source": [
    "## Create the generator\n",
    "\n",
    "It mirrors the discriminator, replacing `Conv2D` layers with `Conv2DTranspose` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ex0fuB4Hv4CQ",
    "outputId": "4c3db4bc-248a-4ade-f1fa-428fa8580e37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 8192)              1056768   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 128)      262272    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      524544    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 512)      2097664   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 3)         38403     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,979,651\n",
      "Trainable params: 3,979,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(8 * 8 * 128),\n",
    "        layers.Reshape((8, 8, 128)),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnYJKlrTv4CQ"
   },
   "source": [
    "## Override `train_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1FHP5eXYv4CR"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9YRt9ouv4CR"
   },
   "source": [
    "## Create a callback that periodically saves generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3KSilKVav4CR"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(\"generated_img_%03d_%d.png\" % (epoch, i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgKUEkDxv4CS"
   },
   "source": [
    "## Train the end-to-end model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "t2VUAB8gv4CS",
    "outputId": "5a9b8702-9b10-4c96-b113-212a536bf8fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1446/6332 [=====>........................] - ETA: 35:54 - d_loss: 0.5382 - g_loss: 1.4653"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m gan \u001b[39m=\u001b[39m GAN(discriminator\u001b[39m=\u001b[39mdiscriminator, generator\u001b[39m=\u001b[39mgenerator, latent_dim\u001b[39m=\u001b[39mlatent_dim)\n\u001b[0;32m      4\u001b[0m gan\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m      5\u001b[0m     d_optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m),\n\u001b[0;32m      6\u001b[0m     g_optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m),\n\u001b[0;32m      7\u001b[0m     loss_fn\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(),\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m gan\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     11\u001b[0m     dataset, epochs\u001b[39m=\u001b[39;49mepochs, callbacks\u001b[39m=\u001b[39;49m[GANMonitor(num_img\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, latent_dim\u001b[39m=\u001b[39;49mlatent_dim)]\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[0;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1158\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\ROHIT SANJAY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1   # In practice, use ~100 epochs\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DY-dcFc8v4CS"
   },
   "source": [
    "Some of the last generated images around epoch 30\n",
    "(results keep improving after that):\n",
    "\n",
    "![results](https://i.imgur.com/h5MtQZ7l.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7759025329696681180\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "dcgan_overriding_train_step",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
